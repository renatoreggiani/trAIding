{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "    !pip install requests_html\n",
    "    !pip install wrapt --upgrade --ignore-installed\n",
    "    !pip install tensorflow\n",
    "    !pip3 install pandas numpy matplotlib yahoo_fin sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/74 [=====>........................] - ETA: 25s - loss: 0.0068 - mean_absolute_error: 0.0611"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-50863d1e1db8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"X_test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y_test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                     verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 3193.29$\n",
      "huber_loss loss: 9.001752914628014e-05\n",
      "Mean Absolute Error: 23.398278375399716\n",
      "Accuracy score: 0.5875850340136054\n",
      "Total buy profit: 11287.449017763138\n",
      "Total sell profit: -579.5377967357635\n",
      "Total profit: 10707.911221027374\n",
      "Profit per trade: 9.105366684547088\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   open         high          low        close     adjclose  \\\n",
      "2020-09-29  3175.389893  3188.260010  3132.540039  3144.879883  3144.879883   \n",
      "2020-10-01  3208.000000  3224.000000  3172.000000  3221.260010  3221.260010   \n",
      "2020-10-09  3210.000000  3288.989990  3197.830078  3286.649902  3286.649902   \n",
      "2020-10-12  3349.939941  3496.239990  3339.550049  3442.929932  3442.929932   \n",
      "2020-10-16  3363.229980  3399.659912  3160.000000  3272.709961  3272.709961   \n",
      "2020-10-20  3222.280029  3266.000000  3192.010010  3217.010010  3217.010010   \n",
      "2020-11-12  3159.949951  3175.879883  3086.050049  3110.280029  3110.280029   \n",
      "2020-11-13  3122.000000  3141.719971  3085.389893  3128.810059  3128.810059   \n",
      "2020-11-17  3183.540039  3189.250000  3135.260010  3135.659912  3135.659912   \n",
      "2020-11-25  3141.870117  3198.000000  3140.260010  3185.070068  3185.070068   \n",
      "\n",
      "             volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2020-09-29  3495800   AMZN  3195.764893       3217.010010   50.885010   \n",
      "2020-10-01  4971900   AMZN  3190.297119       3176.399902    0.000000   \n",
      "2020-10-09  4907900   AMZN  3181.552002       3036.149902    0.000000   \n",
      "2020-10-12  8364200   AMZN  3155.970947       3004.479980    0.000000   \n",
      "2020-10-16  6474400   AMZN  3171.619385       3311.370117 -101.090576   \n",
      "2020-10-20  4509700   AMZN  3183.834473       3035.020020    0.000000   \n",
      "2020-11-12  4362000   AMZN  3209.382080       3162.580078   99.102051   \n",
      "2020-11-13  3756200   AMZN  3205.077148       3158.000000   76.267090   \n",
      "2020-11-17  3444700   AMZN  3200.648193       3104.199951    0.000000   \n",
      "2020-11-25  3790400   AMZN  3202.343262       3236.080078   17.273193   \n",
      "\n",
      "            sell_profit  \n",
      "2020-09-29     0.000000  \n",
      "2020-10-01    30.962891  \n",
      "2020-10-09   105.097900  \n",
      "2020-10-12   286.958984  \n",
      "2020-10-16     0.000000  \n",
      "2020-10-20    33.175537  \n",
      "2020-11-12     0.000000  \n",
      "2020-11-13     0.000000  \n",
      "2020-11-17   -64.988281  \n",
      "2020-11-25     0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
