{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "    !pip install requests_html\n",
    "    !pip install wrapt --upgrade --ignore-installed\n",
    "    !pip install tensorflow\n",
    "    !pip3 install pandas numpy matplotlib yahoo_fin sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load TensorFlow.py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions import get_finance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low'], target_col='target'):\n",
    "    \"\"\"\n",
    "    Get df scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "\n",
    "    result = {}\n",
    "    result['df'] = df.copy()\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df[target_col].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=False)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"VALE3.SA\"\n",
    "df = get_finance_data(ticker, period='1y')\n",
    "df['target'] = df['Close']\n",
    "df = df[['Open', 'High', 'Low', 'target', 'Volume']]\n",
    "\n",
    "# ticker = \"VALE3.SA\"\n",
    "# df = si.get_data(ticker, start_date='20200701', end_date='20201229')\n",
    "# df = df[[\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "LOOKUP_STEP = 1\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "TEST_SIZE = 0.2\n",
    "FEATURE_COLUMNS = list(df.columns)\n",
    "# TARGET_COL = 'Close'\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\"\n",
    "\n",
    "data = load_data(df, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: Fri Jan  1 21:42:56 2021\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00199, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-1-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00199\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00199\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00199 to 0.00190, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-1-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00190\n",
      "Fim: Fri Jan  1 21:43:07 2021\n",
      "Tempo total 0.19 min\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "print('Inicio:', time.ctime(start))\n",
    "\n",
    "# train the model and save the weights whenever we see a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=0, \n",
    "                    use_multiprocessing=True)\n",
    "\n",
    "end = time.time()\n",
    "print('Fim:', time.ctime(end))\n",
    "print('Tempo total', round((end - start)/60, 2), 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"target\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price\n",
    "\n",
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)\n",
    "\n",
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"target\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae\n",
    "\n",
    "\n",
    "\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data, target_col='target'):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price, then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][target_col].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][target_col].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"target_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_target_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[target_col], \n",
    "                                    final_df[f\"target_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_target_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[target_col], \n",
    "                                    final_df[f\"target_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_target_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_target_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'target_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 1 days is 90.87$\n",
      "huber_loss loss: 0.0019041590858250856\n",
      "Mean Absolute Error: 35.62829813758471\n",
      "Accuracy score: 0.55\n",
      "Total buy profit: 52.07923889160156\n",
      "Total sell profit: -27.15270233154297\n",
      "Total profit: 24.926536560058594\n",
      "Profit per trade: 0.6231634140014648\n"
     ]
    }
   ],
   "source": [
    "final_df = get_final_df(model, data)\n",
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)\n",
    "\n",
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low     target    Volume   target_1  \\\n",
      "Date                                                                          \n",
      "2020-12-14  85.199997  85.220001  82.949997  83.550003  20931700  86.489487   \n",
      "2020-12-15  83.550003  85.379997  83.550003  84.500000  18762800  87.022644   \n",
      "2020-12-16  84.900002  86.230003  84.360001  86.220001  23038300  87.530777   \n",
      "2020-12-17  86.500000  87.949997  86.169998  87.199997  21367800  88.077171   \n",
      "2020-12-18  87.620003  88.349998  87.430000  88.190002  13534400  88.655617   \n",
      "2020-12-21  86.150002  87.400002  84.779999  86.860001  31877300  89.161064   \n",
      "2020-12-22  86.860001  86.989998  85.430000  86.940002  23157000  89.580925   \n",
      "2020-12-23  86.529999  87.529999  86.400002  87.360001  17710200  89.940819   \n",
      "2020-12-28  87.790001  88.580002  87.080002  87.309998  26001300  90.298058   \n",
      "2020-12-29  87.970001  88.199997  86.510002  87.070000  19727500  90.606903   \n",
      "\n",
      "            true_target_1  buy_profit  sell_profit  \n",
      "Date                                                \n",
      "2020-12-14      84.500000    2.939484     0.000000  \n",
      "2020-12-15      86.220001    2.522644     0.000000  \n",
      "2020-12-16      87.199997    1.310776     0.000000  \n",
      "2020-12-17      88.190002    0.877174     0.000000  \n",
      "2020-12-18      86.860001    0.000000    -0.465614  \n",
      "2020-12-21      86.940002    2.301064     0.000000  \n",
      "2020-12-22      87.360001    2.640923     0.000000  \n",
      "2020-12-23      87.309998    0.000000    -2.580818  \n",
      "2020-12-28      87.070000    0.000000    -2.988060  \n",
      "2020-12-29      87.449997    3.536903     0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
