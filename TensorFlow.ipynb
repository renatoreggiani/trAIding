{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "    !pip install requests_html\n",
    "    !pip install wrapt --upgrade --ignore-installed\n",
    "    !pip install tensorflow\n",
    "    !pip3 install pandas numpy matplotlib yahoo_fin sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load TensorFlow.py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from functions import get_finance_data\n",
    "\n",
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low'], target_col='adjclose'):\n",
    "    \"\"\"\n",
    "    Get df scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "\n",
    "    result = {}\n",
    "    result['df'] = df.copy()\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    result['last_sequence'] = last_sequence\n",
    "    \n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "#%%\n",
    "\n",
    "# df = get_finance_data('VALE3.SA',period='1y')\n",
    "# df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "ticker = \"VALE3.SA\"\n",
    "df = si.get_data(ticker, start_date='20200701', end_date='20201229')\n",
    "df = df[['open', 'high', 'low', 'close', 'adjclose', 'volume']]\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "N_STEPS = 50\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "TEST_SIZE = 0.2\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "N_LAYERS = 2\n",
    "CELL = LSTM\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50#0\n",
    "\n",
    "\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# load the data\n",
    "data = load_data(df, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS, target_col='adjclose')\n",
    "\n",
    "#%%\n",
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "    \n",
    "# save the dataframe\n",
    "# ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# data[\"df\"].to_csv(ticker_data_filename)\n",
    "#%%\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: Fri Jan  1 15:52:50 2021\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05848, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05848 to 0.03257, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03257\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03257 to 0.01433, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.01433\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.01433\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01433 to 0.01414, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01414 to 0.01322, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01322\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01322\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01322\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01322\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01322\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01322 to 0.01278, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01278 to 0.01259, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.01259\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.01259 to 0.01077, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.01077 to 0.00642, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00642\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00642 to 0.00618, saving model to results\\2021-01-01_VALE3.SA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00618\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00618\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00618\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "print('Inicio:', time.ctime(start))\n",
    "\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=0, \n",
    "                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim: Fri Jan  1 15:53:54 2021\n",
      "Tempo total 1.07 min\n",
      "Future price after 15 days is 110.04$\n",
      "huber_loss loss: 0.006183004006743431\n",
      "Mean Absolute Error: 55.28856845654398\n",
      "Accuracy score: 0.9166666666666666\n",
      "Total buy profit: 64.92063903808594\n",
      "Total sell profit: -2.1915321350097656\n",
      "Total profit: 62.72910690307617\n",
      "Profit per trade: 5.227425575256348\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 open       high        low      close   adjclose    volume  \\\n",
      "2020-09-22  58.139999  58.279999  57.150002  57.810001  57.810001  23996200   \n",
      "2020-09-25  58.349998  59.450001  58.200001  59.250000  59.250000  27582200   \n",
      "2020-10-06  60.009998  60.279999  58.209999  58.619999  58.619999  21951600   \n",
      "2020-10-15  62.410000  62.860001  61.980000  62.470001  62.470001  16309700   \n",
      "2020-10-26  62.900002  63.450001  62.009998  62.500000  62.500000  18250900   \n",
      "2020-11-06  62.380001  63.959999  62.340000  63.340000  63.340000  21039200   \n",
      "2020-11-16  63.500000  65.339996  62.970001  64.919998  64.919998  91477900   \n",
      "2020-11-27  77.000000  78.779999  76.769997  78.199997  78.199997  35777100   \n",
      "2020-12-01  79.830002  81.500000  79.250000  81.250000  81.250000  61441200   \n",
      "2020-12-03  81.000000  81.050003  78.610001  78.959999  78.959999  35158600   \n",
      "\n",
      "            adjclose_15  true_adjclose_15  buy_profit  sell_profit  \n",
      "2020-09-22    63.316311         63.000000    5.506310          0.0  \n",
      "2020-09-25    62.559513         61.950001    3.309513          0.0  \n",
      "2020-10-06    60.686409         60.259998    2.066410          0.0  \n",
      "2020-10-15    62.729614         63.340000    0.259613          0.0  \n",
      "2020-10-26    68.092369         66.970001    5.592369          0.0  \n",
      "2020-11-06    71.512405         78.000000    8.172405          0.0  \n",
      "2020-11-16    73.843033         82.900002    8.923035          0.0  \n",
      "2020-11-27    83.741928         88.190002    5.541931          0.0  \n",
      "2020-12-01    88.044029         86.940002    6.794029          0.0  \n",
      "2020-12-03    92.224312         87.309998   13.264313          0.0  \n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print('Fim:', time.ctime(end))\n",
    "print('Tempo total', round((end - start)/60, 2), 'min')\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price, then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae\n",
    "\n",
    "\n",
    "# In[223]:\n",
    "\n",
    "final_df = get_final_df(model, data)\n",
    "future_price = predict(model, data)\n",
    "\n",
    "# In[145]:\n",
    "\n",
    "    # we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)\n",
    "\n",
    "\n",
    "# In[219]:\n",
    "\n",
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)\n",
    "\n",
    "\n",
    "# In[147]:\n",
    "\n",
    "    # plot true/pred prices graph\n",
    "plot_graph(final_df)\n",
    "\n",
    "\n",
    "# In[101]:\n",
    "\n",
    "\n",
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
